# LangChain & LangGraph 위키

## CH01 LangChain 시작하기
- [01. 설치 영상보고 따라하기](https://wikidocs.net/153263)
- [02. OpenAI API 키 발급 및 테스트](https://wikidocs.net/153264)
- [03. LangSmith 추적 설정](https://wikidocs.net/153265)
- [04. OpenAI API 사용(GPT-4o 멀티모달)](https://wikidocs.net/153266)
- [05. LangChain Expression Language(LCEL)](https://wikidocs.net/153267)
- [06. LCEL 인터페이스](https://wikidocs.net/153268)
- [07. Runnable](https://wikidocs.net/153269)

## CH02 프롬프트(Prompt)
- [01. 프롬프트(Prompt)](https://wikidocs.net/153270)
- [02. 퓨샷 프롬프트(FewShotPromptTemplate)](https://wikidocs.net/153271)
- [03. LangChain Hub](https://wikidocs.net/153272)
- [04. 개인화된 프롬프트(Hub에 업로드)](https://wikidocs.net/153273)

## CH03 출력 파서(Output Parsers)
- [01. Pydantic 출력 파서(PydanticOutputParser)](https://wikidocs.net/153274)
- [02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)](https://wikidocs.net/153275)
- [03. 구조화된 출력 파서(StructuredOuputParser)](https://wikidocs.net/153276)
- [04. JSON 출력 파서(JsonOutputParser)](https://wikidocs.net/153277)
- [05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)](https://wikidocs.net/153278)
- [06. 날짜 형식 출력 파서(DatetimeOutputParser)](https://wikidocs.net/153279)
- [07. 열거형 출력 파서(EnumOutputParser)](https://wikidocs.net/153280)
- [08. 출력 수정 파서(OutputFixingParser)](https://wikidocs.net/153281)

## CH04 모델(Model)
- [01. 다양한 LLM 모델 활용](https://wikidocs.net/153282)
- [02. 캐싱(Cache)](https://wikidocs.net/153283)
- [03. 모델 직렬화(Serialization) - 저장 및 불러오기](https://wikidocs.net/153284)
- [04. 토큰 사용량 확인](https://wikidocs.net/153285)
- [05. 구글 생성 AI(Google Generative AI)](https://wikidocs.net/153286)
- [06. 허깅페이스 엔드포인트(HuggingFace Endpoints)](https://wikidocs.net/153287)
- [07. 허깅페이스 로컬(HuggingFace Local)](https://wikidocs.net/153288)
- [08. 허깅페이스 파이프라인(HuggingFace Pipeline)](https://wikidocs.net/153289)
- [09. 올라마(Ollama)](https://wikidocs.net/153290)
- [10. GPT4ALL](https://wikidocs.net/153291)
- [11. 비디오(Video) 질의 응답 LLM (Gemini)](https://wikidocs.net/153292)

## CH05 메모리(Memory)
- [01. 대화 버퍼 메모리(ConversationBufferMemory)](https://wikidocs.net/153293)
- [02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)](https://wikidocs.net/153294)
- [03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)](https://wikidocs.net/153295)
- [04. 대화 엔티티 메모리(ConversationEntityMemory)](https://wikidocs.net/153296)
- [05. 대화 지식그래프 메모리(ConversationKGMemory)](https://wikidocs.net/153297)
- [06. 대화 요약 메모리(ConversationSummaryMemory)](https://wikidocs.net/153298)
- [07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)](https://wikidocs.net/153299)
- [08. LCEL Chain 에 메모리 추가](https://wikidocs.net/153300)
- [09. SQLite 에 대화내용 저장](https://wikidocs.net/153301)
- [10. RunnableWithMessageHistory에 ChatMessageHistory추가](https://wikidocs.net/153302)

## CH06 문서 로더(Document Loader)
- [01. 도큐먼트(Document) 의 구조](https://wikidocs.net/153303)
- [02. PDF](https://wikidocs.net/153304)
- [03. 한글(HWP)](https://wikidocs.net/153305)
- [04. CSV](https://wikidocs.net/153306)
- [05. Excel](https://wikidocs.net/153307)
- [06. Word](https://wikidocs.net/153308)
- [07. PowerPoint](https://wikidocs.net/153309)
- [08. 웹 문서(WebBaseLoader)](https://wikidocs.net/153310)
- [09. 텍스트(TextLoader)](https://wikidocs.net/153311)
- [10. JSON](https://wikidocs.net/153312)
- [11. Arxiv](https://wikidocs.net/153313)
- [12. UpstageLayoutAnalysisLoader](https://wikidocs.net/153314)
- [13. LlamaParser](https://wikidocs.net/153315)

## CH07 텍스트 분할(Text Splitter)
- [01. 문자 텍스트 분할(CharacterTextSplitter)](https://wikidocs.net/153316)
- [02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)](https://wikidocs.net/153317)
- [03. 토큰 텍스트 분할(TokenTextSplitter)](https://wikidocs.net/153318)
- [04. 시멘틱 청커(SemanticChunker)](https://wikidocs.net/153319)
- [05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)](https://wikidocs.net/153320)
- [06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)](https://wikidocs.net/153321)
- [07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)](https://wikidocs.net/153322)
- [08. 재귀적 JSON 분할(RecursiveJsonSplitter)](https://wikidocs.net/153323)

## CH08 임베딩(Embedding)
- [01. OpenAIEmbeddings](https://wikidocs.net/153324)
- [02. 캐시 임베딩(CacheBackedEmbeddings)](https://wikidocs.net/153325)
- [03. 허깅페이스 임베딩(HuggingFace Embeddings)](https://wikidocs.net/153326)
- [04. UpstageEmbeddings](https://wikidocs.net/153327)
- [05. OllamaEmbeddings](https://wikidocs.net/153328)
- [06. GPT4ALL 임베딩](https://wikidocs.net/153329)
- [07. Llama CPP 임베딩](https://wikidocs.net/153330)

## CH09 벡터저장소(VectorStore)
- [01. Chroma](https://wikidocs.net/153331)
- [02. FAISS](https://wikidocs.net/153332)
- [03. Pinecone](https://wikidocs.net/153333)

## CH10 검색기(Retriever)
- [01. 벡터스토어 기반 검색기(VectorStore-backed Retriever)](https://wikidocs.net/153334)
- [02. 문맥 압축 검색기(ContextualCompressionRetriever)](https://wikidocs.net/153335)
- [03. 앙상블 검색기(EnsembleRetriever)](https://wikidocs.net/153336)
- [04. 긴 문맥 재정렬(LongContextReorder)](https://wikidocs.net/153337)
- [05. 상위 문서 검색기(ParentDocumentRetriever)](https://wikidocs.net/153338)
- [06. 다중 쿼리 검색기(MultiQueryRetriever)](https://wikidocs.net/153339)
- [07. 다중 벡터저장소 검색기(MultiVectorRetriever)](https://wikidocs.net/153340)
- [08. 셀프 쿼리 검색기(SelfQueryRetriever)](https://wikidocs.net/153341)
- [09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)](https://wikidocs.net/153342)
- [10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기](https://wikidocs.net/153343)
- [11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever)](https://wikidocs.net/153344)

## CH11 리랭커(Reranker)
- [01. Cross Encoder Reranker](https://wikidocs.net/153345)
- [02. Cohere Reranker](https://wikidocs.net/153346)
- [03. Jina Reranker](https://wikidocs.net/153347)
- [04. FlashRank Reranker](https://wikidocs.net/153348)

## CH12 Retrieval Augmented Generation(RAG)
- [01. PDF 문서 기반 QA(Question-Answer)](https://wikidocs.net/153349)
- [02. 네이버 뉴스기사 QA(Question-Answer)](https://wikidocs.net/153350)
- [03. RAG 의 기능별 다양한 모듈 활용기](https://wikidocs.net/153351)
- [04. RAPTOR: 긴 문맥 요약(Long Context Summary)](https://wikidocs.net/153352)
- [05. 대화내용을 기억하는 RAG 체인](https://wikidocs.net/153353)
- [06. 자기 탐색 RAG(Self-RAG)](https://wikidocs.net/153354)
- [07. 교정적 RAG(CRAG, Corrective RAG)](https://wikidocs.net/153355)

## CH13 LangChain Expression Language(LCEL)
- [01. RunnablePassthrough](https://wikidocs.net/153356)
- [02. Runnable 구조(그래프) 검토](https://wikidocs.net/153357)
- [03. RunnableLambda](https://wikidocs.net/153358)
- [04. LLM 체인 라우팅(RunnableLambda, RunnableBranch)](https://wikidocs.net/153359)
- [05. RunnableParallel](https://wikidocs.net/153360)
- [06. 동적 속성 지정(configurable_fields, configurable_alternatives)](https://wikidocs.net/153361)
- [07. @chain 데코레이터로 Runnable 구성](https://wikidocs.net/153362)
- [08. RunnableWithMessageHistory](https://wikidocs.net/153363)
- [09. 사용자 정의 제네레이터(generator)](https://wikidocs.net/153364)
- [10. Runtime Arguments](https://wikidocs.net/153365)

## CH14 LangGraph
- [01. LangGraph 소개](https://langchain-ai.github.io/langgraph/tutorials/introduction/)
- [02. LangGraph 빠른 시작](https://langchain-ai.github.io/langgraph/tutorials/introduction/)
- [03. LangGraph 주요 개념](https://langchain-ai.github.io/langgraph/concepts/high_level/)
   - [그래프 API 기본](https://langchain-ai.github.io/langgraph/concepts/low_level/)
   - [상태 관리](https://langchain-ai.github.io/langgraph/how-tos/state-model/)
   - [지속성(Persistence)](https://langchain-ai.github.io/langgraph/concepts/persistence/)
   - [휴먼 인 더 루프(Human-in-the-loop)](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
   - [타임 트래블(Time Travel)](https://langchain-ai.github.io/langgraph/concepts/time-travel/)
   - [스트리밍(Streaming)](https://langchain-ai.github.io/langgraph/concepts/streaming/)
   - [기능적 API(Functional API)](https://langchain-ai.github.io/langgraph/concepts/functional_api/)
   - [내구성 실행(Durable Execution)](https://langchain-ai.github.io/langgraph/concepts/durable_execution/)
   - [Pregel](https://langchain-ai.github.io/langgraph/concepts/pregel/)
   - [자주 묻는 질문(FAQ)](https://langchain-ai.github.io/langgraph/concepts/faq/)
- [04. 에이전트 패턴](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
   - [순차 에이전트](https://langchain-ai.github.io/langgraph/how-tos/sequence/)
   - [계획 후 실행(Plan-and-Execute)](https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/)
   - [노드 재시도 추가](https://langchain-ai.github.io/langgraph/how-tos/node-retries/)
   - [재귀 제한 추가](https://langchain-ai.github.io/langgraph/how-tos/recursion-limit/)
   - [재귀 제한 도달 시 상태 반환](https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/)
- [05. 멀티 에이전트 시스템](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)
   - [멀티 에이전트 네트워크](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network/)
   - [멀티 에이전트 감독자(Multi-Agent Supervisor)](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/)
   - [계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams)](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/)
   - [SQL 데이터베이스와 상호작용하는 에이전트](https://langchain-ai.github.io/langgraph/tutorials/sql-agent/)
   - [STORM 개념을 도입한 연구를 위한 멀티 에이전트](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/)
   - [에이전트 간 전환 구현](https://langchain-ai.github.io/langgraph/how-tos/agent-handoffs/)
   - [멀티 에이전트 멀티턴 대화](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/)
- [06. 그래프 기능 및 도구](https://langchain-ai.github.io/langgraph/how-tos/)
   - [그래프 시각화](https://langchain-ai.github.io/langgraph/how-tos/visualization/)
   - [맵-리듀스 브랜치 만들기](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
   - [상태 업데이트 및 노드 이동](https://langchain-ai.github.io/langgraph/how-tos/command/)
   - [그래프 비동기 실행](https://langchain-ai.github.io/langgraph/how-tos/async/)
   - [서브그래프 사용](https://langchain-ai.github.io/langgraph/how-tos/subgraph/)
   - [서브그래프에서 상태 보기 및 업데이트](https://langchain-ai.github.io/langgraph/how-tos/subgraphs-manage-state/)
   - [서브그래프 입력 및 출력 변환](https://langchain-ai.github.io/langgraph/how-tos/subgraph-transform-state/)
   - [서브그래프 지속성 추가](https://langchain-ai.github.io/langgraph/how-tos/subgraph-persistence/)
- [07. 도구 호출](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)
   - [ToolNode를 사용한 도구 호출](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)
   - [도구 호출 오류 처리](https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/)
   - [런타임 값을 도구에 전달](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/)
   - [도구에 구성 전달](https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/)
   - [도구에서 그래프 상태 업데이트](https://langchain-ai.github.io/langgraph/how-tos/update-state-from-tools/)
   - [대량의 도구 처리](https://langchain-ai.github.io/langgraph/how-tos/many-tools/)
   - [도구 호출 에이전트에서 구조화된 출력 강제](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/)
- [08. 메모리 관리](https://langchain-ai.github.io/langgraph/how-tos/memory/)
   - [대화 기록 관리](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)
   - [메시지 삭제](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/)
   - [요약 대화 메모리 추가](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/)
   - [장기 메모리 추가(cross-thread)](https://langchain-ai.github.io/langgraph/how-tos/memory/cross-thread-persistence/)
   - [장기 메모리용 시맨틱 검색](https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/)
- [09. 스트리밍](https://langchain-ai.github.io/langgraph/how-tos/streaming/)
   - [스트리밍 구현 방법](https://langchain-ai.github.io/langgraph/how-tos/streaming/)
   - [LLM 토큰 스트리밍](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/)
   - [특정 노드에서 LLM 토큰 스트리밍](https://langchain-ai.github.io/langgraph/how-tos/streaming-specific-nodes/)
   - [도구 내에서 데이터 스트리밍](https://langchain-ai.github.io/langgraph/how-tos/streaming-events-from-within-tools/)
   - [서브그래프에서 스트리밍](https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/)
   - [스트리밍을 지원하지 않는 모델 비활성화](https://langchain-ai.github.io/langgraph/how-tos/disable-streaming/)
- [10. 휴먼 인 더 루프](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)
   - [사용자 입력 대기](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/)
   - [도구 호출 검토](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/)
   - [정적 브레이크포인트 추가](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/)
   - [그래프 상태 편집](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)
   - [사용자 입력 대기(Functional API)](https://langchain-ai.github.io/langgraph/how-tos/wait-user-input-functional/)
   - [도구 호출 검토(Functional API)](https://langchain-ai.github.io/langgraph/how-tos/review-tool-calls-functional/)
- [11. 지속성 관리](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
   - [스레드 수준 지속성 추가](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
   - [크로스 스레드 지속성 추가](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/)
   - [PostgreSQL 체크포인터 사용](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)
   - [MongoDB 체크포인터 사용](https://langchain-ai.github.io/langgraph/how-tos/persistence_mongodb/)
   - [Redis를 사용한 사용자 정의 체크포인터 만들기](https://langchain-ai.github.io/langgraph/how-tos/persistence_redis/)
   - [스레드 수준 지속성(Functional API)](https://langchain-ai.github.io/langgraph/how-tos/persistence-functional/)
   - [크로스 스레드 지속성(Functional API)](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence-functional/)
- [12. 사용 사례 및 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)
   - [고객 지원 시스템](https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/)
   - [사용자 요구사항에서 프롬프트 생성](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting/)
   - [코드 어시스턴트](https://langchain-ai.github.io/langgraph/tutorials/code_assistant/langgraph_code_assistant/)
   - [LangGraph 서버 빠른 시작](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)
   - [LangGraph Cloud 사용 배포](https://langchain-ai.github.io/langgraph/cloud/quick_start/)

## CH15 LangGraph 오픈 튜토리얼
- [01. 핵심 기능](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features)
   - [LangGraph에서 사용되는 Python 문법 이해](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/understanding-common-python-syntax-used-in-langgraph)
   - [LangGraph로 기본 챗봇 구축하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/building-a-basic-chatbot-with-langgraph)
   - [LangGraph로 에이전트 구축하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/building-an-agent-with-langgraph)
   - [메모리가 있는 에이전트](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/agent-with-memory)
   - [휴먼-인-더-루프](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/human-in-the-loop)
   - [인간에게 도움 요청하기: LangGraph에서 상태 커스터마이징](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/asking-humans-for-help-customizing-state-in-langgraph)
   - [메시지 삭제](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/deletemessages)
   - [LangGraph ToolNode](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/langgraph-toolnode)
   - [병렬 노드 실행을 위한 브랜치 생성](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/branch-creation-for-parallel-node-execution)
   - [LangGraph로 대화 요약하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/conversation-summaries-with-langgraph)
   - [LangGraph 서브그래프](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/langgrpah-subgraph)
   - [서브그래프의 입력과 출력 변환 방법](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/how-to-transform-the-input-and-output-of-a-subgraph)
   - [LangGraph 스트리밍 모드](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/langgraph-streaming-mode)
   - [에러 처리](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/errors)
- [02. 구조](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures)
   - [LangGraph 그래프 구축하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures/langgraph-building-graphs)
   - [기본 RAG](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures/naive-rag)
   - [근거 검사 추가하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures/add-groundedness-check)
   - [쿼리 재작성 추가하기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures/langgraph-add-query-rewrite)
   - [에이전트 RAG](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/02-structures/agentic-rag)
- [03. 사용 사례](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases)
   - [LangGraph 에이전트 시뮬레이션](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/langgraph-agent-simulation)
   - [사용자 요구사항 기반 메타 프롬프트 생성기](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/meta-prompt-generator-based-on-user-requirements)
   - [CRAG: 교정적 RAG](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/crag-corrective-rag)
   - [계획-실행 패턴](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/plan-and-execute)
   - [멀티 에이전트 협업 네트워크](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/multi-agent-collaboration-network)
   - [멀티 에이전트 감독자](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/multi-agent-supervisor)
   - [계층적 멀티 에이전트 팀](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/08-hierarchical-multi-agent-teams)
   - [LangGraph 연구 어시스턴트](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/03-use-cases/10-langgraph-research-assistant)

## CH16 실용 레시피(Cookbook)
- [01. SQL](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/01-sql)
   - [텍스트를 SQL로 변환](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/01-sql/texttosql)
   - [음성을 SQL로 변환](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/01-sql/speechtosql)
- [02. 추천 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/02-recommendationsystem)
   - [이력서 추천 및 리뷰](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/02-recommendationsystem/resumerecommendationreview)
- [03. 그래프 데이터베이스](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/03-graphdb)
   - [그래프 데이터베이스를 활용한 영화 QA 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/03-graphdb/movie-qa-system-with-graph-database)
   - [타이타닉 QA 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/03-graphdb/05-titanicqasystem)
   - [실시간 GraphRAG QA](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/03-graphdb/real-time-graphrag-qa)
- [04. GraphRAG](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/04-graphrag)
   - [학술 검색 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/04-graphrag/academic-search-system)
   - [GraphRAG를 활용한 학술 QA 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/04-graphrag/academic-qa-system-with-graphrag)
- [05. AI 메모리 관리 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/05-aimemorymanagement)
   - [대화 메모리 관리 시스템](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/05-aimemorymanagement/conversationmemorymanagementSystem)
- [06. 멀티모달](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/06-multimodal)
   - [멀티모달 RAG](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/19-cookbook/06-multimodal/multimodal-rag)

## Quickstart

These guides are designed to help you get started with LangGraph.

- [LangGraph Quickstart](https://langchain-ai.github.io/langgraph/tutorials/introduction/): Build a chatbot that can use tools and keep track of conversation history. Add human-in-the-loop capabilities and explore how time-travel works.
- [Common Workflows](https://langchain-ai.github.io/langgraph/tutorials/workflows/): Overview of the most common workflows using LLMs implemented with LangGraph.
- [LangGraph Server Quickstart](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/): Launch a LangGraph server locally and interact with it using REST API and LangGraph Studio Web UI.
- [Deploy with LangGraph Cloud Quickstart](https://langchain-ai.github.io/langgraph/cloud/quick_start/): Deploy a LangGraph app using LangGraph Cloud.

## Concepts

These guides provide explanations of the key concepts behind the LangGraph framework.

- [Why LangGraph?](https://langchain-ai.github.io/langgraph/concepts/high_level/): Motivation for LangGraph, a library for building agentic applications with LLMs.
- [LangGraph Glossary](https://langchain-ai.github.io/langgraph/concepts/low_level/): LangGraph workflows are designed as graphs, with nodes representing different components and edges representing the flow of information between them. This guide provides an overview of the key concepts associated with LangGraph graph primitives.
- [Common Agentic Patterns](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/): An agent uses an LLM to pick its own control flow to solve more complex problems! Agents are a key building block in many LLM applications. This guide explains the different types of agent architectures and how they can be used to control the flow of an application.
- [Multi-Agent Systems](https://langchain-ai.github.io/langgraph/concepts/multi_agent/): Complex LLM applications can often be broken down into multiple agents, each responsible for a different part of the application. This guide explains common patterns for building multi-agent systems.
- [Breakpoints](https://langchain-ai.github.io/langgraph/concepts/breakpoints/): Breakpoints allow pausing the execution of a graph at specific points. Breakpoints allow stepping through graph execution for debugging purposes.
- [Human-in-the-Loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): Explains different ways of integrating human feedback into a LangGraph application.
- [Time Travel](https://langchain-ai.github.io/langgraph/concepts/time-travel/): Time travel allows you to replay past actions in your LangGraph application to explore alternative paths and debug issues.
- [Persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/): LangGraph has a built-in persistence layer, implemented through checkpointers. This persistence layer helps to support powerful capabilities like human-in-the-loop, memory, time travel, and fault-tolerance.
- [Memory](https://langchain-ai.github.io/langgraph/concepts/memory/): Memory in AI applications refers to the ability to process, store, and effectively recall information from past interactions. With memory, your agents can learn from feedback and adapt to users' preferences.
- [Streaming](https://langchain-ai.github.io/langgraph/concepts/streaming/): Streaming is crucial for enhancing the responsiveness of applications built on LLMs. By displaying output progressively, even before a complete response is ready, streaming significantly improves user experience (UX), particularly when dealing with the latency of LLMs.
- [Functional API](https://langchain-ai.github.io/langgraph/concepts/functional_api/): `@entrypoint` and `@task` decorators that allow you to add LangGraph functionality to an existing codebase.
- [Durable Execution](https://langchain-ai.github.io/langgraph/concepts/durable_execution/): LangGraph's built-in [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) layer provides durable execution for workflows, ensuring that the state of each execution step is saved to a durable store. 
- [Pregel](https://langchain-ai.github.io/langgraph/concepts/pregel/): Pregel is LangGraph's runtime, which is responsible for managing the execution of LangGraph applications.
- [FAQ](https://langchain-ai.github.io/langgraph/concepts/faq/): Frequently asked questions about LangGraph.

### Graph API Basics

- [How to update graph state from nodes](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/)
- [How to create a sequence of steps](https://langchain-ai.github.io/langgraph/how-tos/sequence/)
- [How to create branches for parallel execution](https://langchain-ai.github.io/langgraph/how-tos/branching/)
- [How to create and control loops with recursion limits](https://langchain-ai.github.io/langgraph/how-tos/recursion-limit/)
- [How to visualize your graph](https://langchain-ai.github.io/langgraph/how-tos/visualization/)

### Fine-grained Control

These guides demonstrate LangGraph features that grant fine-grained control over the execution of your graph.

- [How to create map-reduce branches for parallel execution](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
- [How to update state and jump to nodes in graphs and subgraphs](https://langchain-ai.github.io/langgraph/how-tos/command/)
- [How to add runtime configuration to your graph](https://langchain-ai.github.io/langgraph/how-tos/configuration/)
- [How to add node retries](https://langchain-ai.github.io/langgraph/how-tos/node-retries/)
- [How to return state before hitting recursion limit](https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/)

### Persistence
 
Persistence makes it easy to persist state across graph runs (per-thread persistence) and across threads (cross-thread persistence). 

These how-to guides show how to add persistence to your graph.

- [How to add thread-level persistence to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
- [How to add thread-level persistence to a subgraph](https://langchain-ai.github.io/langgraph/how-tos/subgraph-persistence/)
- [How to add cross-thread persistence to your graph](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/)
- [How to use Postgres checkpointer for persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)
- [How to use MongoDB checkpointer for persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence_mongodb/)
- [How to create a custom checkpointer using Redis](https://langchain-ai.github.io/langgraph/how-tos/persistence_redis/)

See the below guides for how-to add persistence to your workflow using the [Functional API](https://langchain-ai.github.io/langgraph/concepts/functional_api/):

- [How to add thread-level persistence (functional API)](https://langchain-ai.github.io/langgraph/how-tos/persistence-functional/)
- [How to add cross-thread persistence (functional API)](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence-functional/)

### Memory

LangGraph makes it easy to manage conversation memory in your graph. These how-to guides show how to implement different strategies for that.

- [How to manage conversation history](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)
- [How to delete messages](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/)
- [How to add summary conversation memory](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/)
- [How to add long-term memory (cross-thread)](https://langchain-ai.github.io/langgraph/how-tos/memory/cross-thread-persistence/)
- [How to use semantic search for long-term memory](https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/)

### Human-in-the-loop

Human-in-the-loop functionality allows you to involve humans in the decision-making process of your graph.

These how-to guides show how to implement human-in-the-loop workflows in your graph.

- [How to wait for user input](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/): A basic example that shows how to implement a human-in-the-loop workflow in your graph using the `interrupt` function.
- [How to review tool calls](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/): Incorporate human-in-the-loop for reviewing/editing/accepting tool call requests before they executed using the `interrupt` function.
- [How to add static breakpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/): Use for debugging purposes. For human-in-the-loop workflows, we recommend the [`interrupt` function](https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.interrupt) instead.
- [How to edit graph state](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/): Edit graph state using `graph.update_state` method. Use this if implementing a **human-in-the-loop** workflow via **static breakpoints**.

See the below guides for how-to implement human-in-the-loop workflows with the Functional API.

- [How to wait for user input (Functional API)](https://langchain-ai.github.io/langgraph/how-tos/wait-user-input-functional/)
- [How to review tool calls (Functional API)](https://langchain-ai.github.io/langgraph/how-tos/review-tool-calls-functional/)

### Time Travel

[Time travel](https://langchain-ai.github.io/langgraph/concepts/time-travel/) allows you to replay past actions in your LangGraph application to explore alternative paths and debug issues. These how-to guides show how to use time travel in your graph.

- [How to view and update past graph state](https://langchain-ai.github.io/langgraph/how-tos/time-travel/)

### Streaming

[Streaming](https://langchain-ai.github.io/langgraph/concepts/streaming/) is crucial for enhancing the responsiveness of applications built on LLMs. By displaying output progressively, even before a complete response is ready, streaming significantly improves user experience (UX), particularly when dealing with the latency of LLMs.

- [How to stream](https://langchain-ai.github.io/langgraph/how-tos/streaming/)
- [How to stream LLM tokens](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/)
- [How to stream LLM tokens from specific nodes](https://langchain-ai.github.io/langgraph/how-tos/streaming-specific-nodes/)
- [How to stream data from within a tool](https://langchain-ai.github.io/langgraph/how-tos/streaming-events-from-within-tools/)
- [How to stream from subgraphs](https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/)
- [How to disable streaming for models that don't support it](https://langchain-ai.github.io/langgraph/how-tos/disable-streaming/)

### Tool calling

[Tool calling](https://python.langchain.com/docs/concepts/tool_calling/) is a type of [chat model](https://python.langchain.com/docs/concepts/chat_models/) API.

It accepts tool schemas, along with messages, as input and returns invocations of those tools as part of the output message.

These how-to guides show common patterns for tool calling with LangGraph:

- [How to call tools using ToolNode](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)
- [How to handle tool calling errors](https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/)
- [How to pass runtime values to tools](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/)
- [How to pass config to tools](https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/)
- [How to update graph state from tools](https://langchain-ai.github.io/langgraph/how-tos/update-state-from-tools/)
- [How to handle large numbers of tools](https://langchain-ai.github.io/langgraph/how-tos/many-tools/)

### Subgraphs

Subgraphs allow you to reuse an existing graph from another graph. 

These how-to guides show how to use subgraphs:

- [How to use subgraphs](https://langchain-ai.github.io/langgraph/how-tos/subgraph/)
- [How to view and update state in subgraphs](https://langchain-ai.github.io/langgraph/how-tos/subgraphs-manage-state/)
- [How to transform inputs and outputs of a subgraph](https://langchain-ai.github.io/langgraph/how-tos/subgraph-transform-state/)

### Multi-agent

Multi-agent systems are useful to break down complex LLM applications into multiple agents, each responsible for a different part of the application. 

These how-to guides show how to implement multi-agent systems in LangGraph:

- [How to implement handoffs between agents](https://langchain-ai.github.io/langgraph/how-tos/agent-handoffs/)
- [How to build a multi-agent network](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network/)
- [How to add multi-turn conversation in a multi-agent application](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/)

### State Management

- [How to use Pydantic model as graph state](https://langchain-ai.github.io/langgraph/how-tos/state-model/)
- [How to define input/output schema for your graph](https://langchain-ai.github.io/langgraph/how-tos/input_output_schema/)
- [How to pass private state between nodes inside the graph](https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/)

### Other

- [How to run graph asynchronously](https://langchain-ai.github.io/langgraph/how-tos/async/)
- [How to force tool-calling agent to structure output](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/)
- [How to pass custom LangSmith run ID for graph runs](https://langchain-ai.github.io/langgraph/how-tos/run-id-langsmith/)
- [How to integrate LangGraph with AutoGen, CrewAI, and other frameworks](https://langchain-ai.github.io/langgraph/how-tos/autogen-integration/)

## Use cases 

Explore practical implementations tailored for specific scenarios:

### Chatbots

- [Customer Support](https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/): Build a multi-functional support bot for flights, hotels, and car rentals.
- [Prompt Generation from User Requirements](https://langchain-ai.github.io/langgraph/tutorials/chatbots/information-gather-prompting/): Build an information gathering chatbot.
- [Code Assistant](https://langchain-ai.github.io/langgraph/tutorials/code_assistant/langgraph_code_assistant/): Build a code analysis and generation assistant.

### RAG

- [Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/): Use an agent to figure out how to retrieve the most relevant information before using the retrieved information to answer the user's question.
- [Adaptive RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/): Adaptive RAG is a strategy for RAG that unites (1) query analysis with (2) active / self-corrective RAG. Implementation of: https://arxiv.org/abs/2403.14403
    - For a version that uses a local LLM: [Adaptive RAG using local LLMs](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag_local/)
- [Corrective RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/): Uses an LLM to grade the quality of the retrieved information from the given source, and if the quality is low, it will try to retrieve the information from another source. Implementation of: https://arxiv.org/pdf/2401.15884.pdf 
    - For a version that uses a local LLM: [Corrective RAG using local LLMs](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag_local/)
- [Self-RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_self_rag/): Self-RAG is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents and generations. Implementation of https://arxiv.org/abs/2310.11511.
    - For a version that uses a local LLM: [Self-RAG using local LLMs](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_self_rag_local/) 
- [SQL Agent](https://langchain-ai.github.io/langgraph/tutorials/sql-agent/): Build a SQL agent that can answer questions about a SQL database.

### Multi-Agent Systems

- [Network](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/): Enable two or more agents to collaborate on a task
- [Supervisor](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/): Use an LLM to orchestrate and delegate to individual agents
- [Hierarchical Teams](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/): Orchestrate nested teams of agents to solve problems

## 참고 자료
- [LangChain 공식 문서](https://python.langchain.com/docs/)
- [LangGraph 공식 문서](https://langchain-ai.github.io/langgraph/)
- [LangChain Hub](https://smith.langchain.com/hub)
- [LangSmith](https://smith.langchain.com/)
- [LangChain 오픈 튜토리얼](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/)

---
본 위키는 [테디노트의 랭체인LangChain 노트](https://wikidocs.net/book/14314)와 [LangGraph 공식 문서](https://langchain-ai.github.io/langgraph/)를 참고하여 작성되었습니다. 